---
hide:
  - toc
---

# What is Cloud Native AI

Cloud Native AI is an AI computing platform based on a cloud-native operating system introduced by DaoCloud (referred to as the DaoCloud AI Computing Platform). The DaoCloud AI Computing Platform provides a software and hardware integrated AI computing experience, integrating heterogeneous computing power, optimizing GPU performance, achieving unified scheduling and operation of computing resources, maximizing computing efficiency, reducing computing costs, and providing optimized AI development frameworks to simplify AI development and deployment, accelerating the implementation of AI applications in various industries.

**Key Features**

- Fully Managed Computing Resources

    Leveraging DCE (DaoCloud Enterprise), it provides powerful infrastructure capabilities, supporting super-large-scale computing clusters, heterogeneous GPUs, and one-stop hosting, as well as a series of software and hardware integrated acceleration solutions such as vGPU.

- Data Orchestration

    Supports data management and orchestration capabilities during model development, providing functions such as dataset management, multi-data source access, dataset preloading, etc. It is optimized from the underlying container storage engine to ensure efficient and stable data processing.

- Development Environment Management

    Meets the needs of MLOps and LLMOps engineers for development environments, providing various development environments including JupyterLab, VSCode (in progress), supporting custom development environments, and one-click mounting of various GPU, dataset, and other resources.

- Task Management

    Supports full lifecycle management of training tasks, providing various ways to quickly create tasks; supports mainstream task frameworks such as Pytorch, TensorFlow, PaddlePaddle, naturally supporting various task scheduling types including single-machine, distributed, multi-node, multi-GPU, etc.

- GPU Management

    Allows viewing of all GPU resources and GPU usage, supports viewing the current and historical running tasks in GPUs, facilitating GPU stress assessment.

- Queue Management

    Supports creating queues and associating them with workspaces to ensure the coordination and isolation of queue resources in various clusters.

**Product Logical Architecture**


[Download DCE 5.0](../../download/index.md){ .md-button .md-button--primary }
[Install DCE 5.0](../../install/index.md){ .md-button .md-button--primary }
[Free Trial](../../dce/license0.md){ .md-button .md-button--primary }
